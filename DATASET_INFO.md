# ğŸ“Š InformaciÃ³n del Dataset - Reddit Depression Dataset

## ğŸ“Œ InformaciÃ³n General

| Campo | Detalle |
|-------|---------|
| **Nombre** | Reddit Depression Dataset |
| **Autor** | Rishabh Kausish |
| **Fuente** | Kaggle |
| **Link** | https://www.kaggle.com/datasets/rishabhkausish/reddit-depression-dataset |
| **TamaÃ±o** | ~7,000+ posts |
| **Formato** | CSV |

---

## ğŸ—‚ï¸ Subreddits Incluidos

El dataset contiene posts de **6 subreddits** diferentes:

### Subreddits Etiquetados como **DepresiÃ³n (Label = 1)**
1. **r/depression** - Comunidad de apoyo para personas con depresiÃ³n
2. **r/SuicideWatch** - Comunidad de apoyo en crisis

### Subreddits Etiquetados como **Normal (Label = 0)**
3. **r/teenagers** - Conversaciones de adolescentes
4. **r/DeepThoughts** - Reflexiones filosÃ³ficas
5. **r/happy** - Posts sobre experiencias positivas
6. **r/posts** - Posts generales

---

## ğŸ“‹ Estructura del Dataset

### Columnas del CSV

| Columna | Tipo | DescripciÃ³n |
|---------|------|-------------|
| **Subreddit** | string | Nombre del subreddit donde se publicÃ³ |
| **Title** | string | TÃ­tulo del post de Reddit |
| **Body** | string | Contenido completo del post |
| **Upvotes** | int | NÃºmero de votos positivos recibidos |
| **Created UTC** | int | Timestamp de creaciÃ³n (epoch time) |
| **Number of Comments** | int | Cantidad de comentarios en el post |
| **Label** | int | Etiqueta: 0 (Normal) o 1 (DepresiÃ³n) |

### Ejemplo de Registro

```csv
Subreddit,Title,Body,Upvotes,Created UTC,Number of Comments,Label
depression,"I feel empty","I don't know what to do anymore. Everything feels meaningless...",156,1609459200,23,1
happy,"Got my dream job!","After months of searching, I finally got hired at my dream company!",892,1609545600,45,0
```

---

## ğŸ“¥ MÃ©todos de Descarga

### MÃ©todo 1: kagglehub (RECOMENDADO - AutomÃ¡tico)

```python
import kagglehub

# Descarga automÃ¡tica del dataset
path = kagglehub.dataset_download("rishabhkausish/reddit-depression-dataset")
print("Path to dataset files:", path)

# El archivo CSV estarÃ¡ en: path/archivo.csv
```

**Ventajas:**
- âœ… Descarga automÃ¡tica
- âœ… No requiere configuraciÃ³n de credenciales
- âœ… Integrado en train_model.py

**InstalaciÃ³n:**
```bash
pip install kagglehub
```

---

### MÃ©todo 2: Kaggle CLI

```bash
# 1. Instalar Kaggle CLI
pip install kaggle

# 2. Configurar credenciales
# Descarga tu kaggle.json desde: https://www.kaggle.com/settings/account
mkdir -p ~/.kaggle
cp kaggle.json ~/.kaggle/
chmod 600 ~/.kaggle/kaggle.json

# 3. Descargar dataset
kaggle datasets download -d rishabhkausish/reddit-depression-dataset

# 4. Descomprimir
unzip reddit-depression-dataset.zip
```

---

### MÃ©todo 3: Descarga Manual

1. **Ve a la pÃ¡gina del dataset:**
   https://www.kaggle.com/datasets/rishabhkausish/reddit-depression-dataset

2. **Inicia sesiÃ³n en Kaggle** (crea cuenta gratuita si no tienes)

3. **Haz clic en "Download"** (botÃ³n azul en la esquina superior derecha)

4. **Descomprime el archivo** descargado

5. **Renombra el archivo** (si es necesario) a: `reddit_depression_dataset.csv`

6. **Coloca el archivo** en el directorio del proyecto `mindsentinel/`

---

## ğŸ“Š EstadÃ­sticas del Dataset

### DistribuciÃ³n de Clases

| Label | DescripciÃ³n | Aproximado |
|-------|-------------|------------|
| 0 | Normal | ~50% |
| 1 | DepresiÃ³n | ~50% |

El dataset estÃ¡ relativamente **balanceado**, lo cual es ideal para entrenamiento.

### DistribuciÃ³n por Subreddit

| Subreddit | Posts Aproximados | Label |
|-----------|------------------|-------|
| r/depression | ~2,500 | 1 |
| r/SuicideWatch | ~1,500 | 1 |
| r/teenagers | ~1,200 | 0 |
| r/DeepThoughts | ~800 | 0 |
| r/happy | ~700 | 0 |
| r/posts | ~300 | 0 |

---

## ğŸ” CaracterÃ­sticas del Texto

### Longitud de Posts

| MÃ©trica | Valor Aproximado |
|---------|-----------------|
| Promedio | 150-300 palabras |
| MÃ­nimo | 10 palabras |
| MÃ¡ximo | 1000+ palabras |

### CaracterÃ­sticas LingÃ¼Ã­sticas

**Posts con DepresiÃ³n (Label = 1):**
- âŒ Palabras negativas: "empty", "hopeless", "alone", "worthless"
- âŒ Primera persona singular: "I", "me", "myself"
- âŒ Tiempo presente: "feel", "am", "can't"
- âŒ Absolutos: "never", "always", "nothing", "everything"
- âŒ Temas: Soledad, desesperanza, ideaciÃ³n suicida

**Posts Normales (Label = 0):**
- âœ… Palabras positivas/neutras: "happy", "excited", "thinking"
- âœ… Diversidad de tiempos verbales
- âœ… Temas variados: Reflexiones, celebraciones, conversaciones casuales

---

## ğŸ§¹ Preprocesamiento Aplicado

En `train_model.py`, el texto pasa por:

1. **CombinaciÃ³n**: Title + Body
2. **Limpieza**:
   - Remover URLs (http, www)
   - Remover menciones (@username, u/username)
   - Remover links de subreddits (r/subreddit)
   - Mantener puntuaciÃ³n emocional (!, ?, ...)
   - Convertir a minÃºsculas
   - Remover nÃºmeros
   - Remover espacios mÃºltiples

3. **TokenizaciÃ³n**: Convertir texto a secuencias numÃ©ricas
4. **Padding**: Normalizar longitud a 200 tokens

---

## âš ï¸ Consideraciones Ã‰ticas

### Uso Apropiado
âœ… **SÃ usar para:**
- InvestigaciÃ³n acadÃ©mica en NLP
- Desarrollo de herramientas de detecciÃ³n temprana
- Estudios de viabilidad tÃ©cnica
- EducaciÃ³n en IA y salud mental

### Uso NO Apropiado
âŒ **NO usar para:**
- DiagnÃ³stico clÃ­nico sin supervisiÃ³n mÃ©dica
- Vigilancia no consentida de usuarios
- Decisiones mÃ©dicas sin validaciÃ³n profesional
- DiscriminaciÃ³n o estigmatizaciÃ³n

### Privacidad
- Los posts son pÃºblicos de Reddit
- No contienen informaciÃ³n personal identificable
- Los nombres de usuario fueron anonimizados
- Timestamps fueron convertidos a epoch time

---

## ğŸ”— Referencias

### Dataset Original
- **Link**: https://www.kaggle.com/datasets/rishabhkausish/reddit-depression-dataset
- **Autor**: Rishabh Kausish
- **Licencia**: Verificar en la pÃ¡gina de Kaggle

### InvestigaciÃ³n Relacionada
- Coppersmith et al. (2015) - "Quantifying Mental Health Signals in Twitter"
- De Choudhury et al. (2013) - "Predicting Depression via Social Media"
- Yates et al. (2017) - "Depression and Self-Harm Risk Assessment in Online Forums"

---

## ğŸ“ CÃ³digo de Ejemplo para Carga

### Con kagglehub (AutomÃ¡tico)

```python
import kagglehub
import pandas as pd
import os

# Descargar dataset
path = kagglehub.dataset_download("rishabhkausish/reddit-depression-dataset")

# Buscar archivo CSV
csv_files = [f for f in os.listdir(path) if f.endswith('.csv')]
dataset_path = os.path.join(path, csv_files[0])

# Cargar con pandas
df = pd.read_csv(dataset_path)

print(f"Dataset cargado: {df.shape[0]} registros")
print(f"Columnas: {df.columns.tolist()}")
print(f"\nDistribuciÃ³n de clases:")
print(df['Label'].value_counts())
```

### Con archivo local

```python
import pandas as pd

# Cargar dataset local
df = pd.read_csv('reddit_depression_dataset.csv')

# Explorar datos
print(f"Total de posts: {len(df)}")
print(f"\nSubreddits Ãºnicos: {df['Subreddit'].nunique()}")
print(df['Subreddit'].value_counts())

# Ver ejemplo de post
print(f"\nEjemplo de post:")
print(f"Title: {df['Title'].iloc[0]}")
print(f"Body: {df['Body'].iloc[0][:200]}...")
print(f"Label: {df['Label'].iloc[0]} ({'DepresiÃ³n' if df['Label'].iloc[0] == 1 else 'Normal'})")
```

---

## ğŸ¯ Uso en MindSentinel

### Flujo de Trabajo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. DESCARGA: kagglehub descarga automÃ¡ticamente       â”‚
â”‚     el dataset de Kaggle                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. CARGA: pandas lee el CSV con 7 columnas            â”‚
â”‚     (Subreddit, Title, Body, Upvotes, etc.)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. PREPROCESAMIENTO: Combina Title + Body y limpia    â”‚
â”‚     el texto (remover URLs, menciones, etc.)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. TOKENIZACIÃ“N: Convierte texto a secuencias         â”‚
â”‚     numÃ©ricas con vocabulario de 10,000 palabras       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. ENTRENAMIENTO: LSTM Bidireccional aprende          â”‚
â”‚     patrones lingÃ¼Ã­sticos de depresiÃ³n                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  6. EVALUACIÃ“N: MÃ©tricas de precisiÃ³n, recall, AUC    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ Troubleshooting

### Error: "No module named 'kagglehub'"
```bash
pip install kagglehub
```

### Error: "Dataset not found"
- Verifica conexiÃ³n a internet
- Intenta descarga manual
- Revisa que el nombre del dataset sea correcto

### Error: "CSV has different columns"
- Verifica que descargaste el dataset correcto
- Comprueba la versiÃ³n del dataset en Kaggle
- Revisa la estructura con: `df.columns.tolist()`

### Error: "Too many missing values"
```python
# Verificar valores nulos
print(df.isnull().sum())

# Limpiar valores nulos
df['Title'] = df['Title'].fillna('')
df['Body'] = df['Body'].fillna('')
df = df.dropna(subset=['Label'])
```

---

## ğŸ“Š MÃ©tricas de Calidad del Dataset

| Aspecto | EvaluaciÃ³n |
|---------|-----------|
| TamaÃ±o | â­â­â­â­ (7K+ posts) |
| Balance | â­â­â­â­â­ (~50/50) |
| Diversidad | â­â­â­â­ (6 subreddits) |
| Limpieza | â­â­â­â­ (pocos nulos) |
| Relevancia | â­â­â­â­â­ (casos reales) |

---

## ğŸ’¡ Consejos para Mejor Rendimiento

1. **Combinar Title + Body**: MÃ¡s contexto = mejor precisiÃ³n
2. **No remover stopwords**: Palabras como "I", "no", "never" son importantes
3. **Mantener puntuaciÃ³n emocional**: !!!, ???, ... indican intensidad
4. **Balancear clases**: Usar class_weight en entrenamiento
5. **ValidaciÃ³n estratificada**: Mantener proporciÃ³n 50/50 en splits

---

## ğŸ“ CitaciÃ³n

Si usas este dataset en investigaciÃ³n acadÃ©mica:

```
Kausish, R. (2023). Reddit Depression Dataset. 
Kaggle. https://www.kaggle.com/datasets/rishabhkausish/reddit-depression-dataset
```

---

**ğŸ“Š Dataset listo para ser usado en MindSentinel**

Para comenzar: `python train_model.py` (descarga automÃ¡tica incluida)
