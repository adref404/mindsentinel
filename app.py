"""
MindSentinel - Sistema Multi-Agente para Monitoreo de Salud Mental
===================================================================
Arquitectura: CrewAI + Google Gemini + Deep Learning (LSTM)
Frontend: Streamlit
Agentes:
    1. Clasificador (Deep Learning)
    2. Explicabilidad XAI (Gemini)
    3. Supervisor/Decisor Final (Gemini)
"""

import streamlit as st
import pickle
import numpy as np
import re
import os
from datetime import datetime
from dotenv import load_dotenv

# TensorFlow
import tensorflow as tf
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.sequence import pad_sequences

# CrewAI y LangChain
# ‚úÖ CORRECCI√ìN: Usar LLM de CrewAI directamente
from crewai import Agent, Task, Crew, Process, LLM

# ============================================================================
# CONFIGURACI√ìN DE LA API DE GOOGLE GEMINI
# ============================================================================
# Cargar variables de entorno
load_dotenv()

# üîë IMPORTANTE: Configura tu API Key de Google Gemini aqu√≠
# Obt√©n tu API Key gratis en: https://makersuite.google.com/app/apikey

# Opci√≥n 1: Variable de entorno (RECOMENDADO para producci√≥n)
# export GOOGLE_API_KEY='tu_api_key_aqui'
# Obtener API Key
GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')

# Validar que la API Key est√© configurada
if not GOOGLE_API_KEY:
    st.error("""
    ‚ö†Ô∏è **API Key no configurada**
    
    Por favor:
    1. Crea un archivo `.env` en la ra√≠z del proyecto
    2. Agrega la l√≠nea: `GOOGLE_API_KEY=tu_api_key_aqui`
    3. Obt√©n tu API Key en: https://aistudio.google.com/app/apikey
    4. Reinicia la aplicaci√≥n
    """)
    st.stop()

# ‚úÖ SOLUCI√ìN: Configurar LLM usando la clase LLM de CrewAI
try:
    llm = LLM(
        model="gemini/gemini-2.5-flash",  # Prefijo "gemini/" es OBLIGATORIO
        api_key=GOOGLE_API_KEY,
        temperature=0.7
    )
    
    # Test opcional: verificar que funciona
    import google.generativeai as genai
    genai.configure(api_key=GOOGLE_API_KEY)
    
except Exception as e:
    st.error(f"""
    ‚ùå **Error al configurar Google Gemini**
    
    Error: {str(e)}
    
    Posibles causas:
    - API Key inv√°lida
    - Sin conexi√≥n a internet
    - L√≠mite de uso excedido
    """)
    st.stop()
# ============================================================================
# CONFIGURACI√ìN DE STREAMLIT
# ============================================================================
st.set_page_config(
    page_title="MindSentinel - Monitoreo de Salud Mental",
    page_icon="üß†",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS personalizado para mejorar la UI
st.markdown("""
    <style>
    .main-header {
        font-size: 3rem;
        font-weight: bold;
        color: #1E88E5;
        text-align: center;
        margin-bottom: 0.5rem;
    }
    .sub-header {
        font-size: 1.2rem;
        color: #666;
        text-align: center;
        margin-bottom: 2rem;
    }
    .prediction-box {
        padding: 20px;
        border-radius: 10px;
        margin: 10px 0;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    .high-risk {
        background-color: #ffebee;
        border-left: 5px solid #f44336;
    }
    .medium-risk {
        background-color: #fff3e0;
        border-left: 5px solid #ff9800;
    }
    .low-risk {
        background-color: #e8f5e9;
        border-left: 5px solid #4caf50;
    }
    .agent-card {
        background-color: #f5f5f5;
        padding: 15px;
        border-radius: 8px;
        margin: 10px 0;
    }
    </style>
""", unsafe_allow_html=True)

# ============================================================================
# CARGA DE ARTEFACTOS DEL MODELO
# ============================================================================
@st.cache_resource
def load_artifacts():
    """
    Carga el modelo LSTM, tokenizador y configuraci√≥n
    El decorador @st.cache_resource evita recargar en cada interacci√≥n
    """
    try:
        # Cargar modelo de Deep Learning
        model = load_model('modelo_depresion.h5')
        
        # Cargar tokenizador
        with open('tokenizer.pickle', 'rb') as handle:
            tokenizer = pickle.load(handle)
        
        # Cargar configuraci√≥n
        with open('model_config.pickle', 'rb') as handle:
            config = pickle.load(handle)
        
        return model, tokenizer, config
    
    except FileNotFoundError as e:
        st.error(f"""
        ‚ùå Error: No se encontraron los artefactos del modelo.
        
        Por favor aseg√∫rate de:
        1. Ejecutar primero el script train_model.py
        2. Copiar los archivos generados a este directorio:
           - modelo_depresion.h5
           - tokenizer.pickle
           - model_config.pickle
        """)
        st.stop()

# Cargar artefactos
model, tokenizer, config = load_artifacts()

# ============================================================================
# FUNCIONES DE PREPROCESAMIENTO
# ============================================================================
def clean_text(text):
    """
    Limpieza de texto (ID√âNTICA a train_model.py)
    """
    if not isinstance(text, str):
        return ""
    
    text = text.lower()
    text = re.sub(r'http\S+|www\S+|https\S+', '', text, flags=re.MULTILINE)
    text = re.sub(r'@\w+', '', text)
    text = re.sub(r'r/\w+', '', text)
    text = re.sub(r'u/\w+', '', text)  # Agregar u/username
    text = re.sub(r'[^\w\s!?.\']', ' ', text)
    text = re.sub(r'\d+', '', text)
    text = re.sub(r'\s+', ' ', text).strip()
    
    return text

def preprocess_for_prediction(text, tokenizer, max_len):
    """
    Preprocesa texto para predicci√≥n del modelo
    """
    cleaned = clean_text(text)
    sequence = tokenizer.texts_to_sequences([cleaned])
    padded = pad_sequences(sequence, maxlen=max_len, padding='post', truncating='post')
    return padded

# ============================================================================
# AGENTE 1: CLASIFICADOR (Deep Learning)
# ============================================================================
def agente_clasificador(text):
    """
    Agente 1: Clasificador de Depresi√≥n usando LSTM
    
    Returns:
        dict: {
            'probabilidad': float,
            'prediccion': str,
            'nivel_riesgo': str,
            'confianza': float
        }
    """
    # Preprocesar texto
    input_data = preprocess_for_prediction(text, tokenizer, config['max_len'])
    
    # Predicci√≥n
    probabilidad = float(model.predict(input_data, verbose=0)[0][0])
    
    # Determinar nivel de riesgo
    if probabilidad >= 0.7:
        nivel_riesgo = "ALTO"
        prediccion = "Indicadores significativos de depresi√≥n"
    elif probabilidad >= 0.4:
        nivel_riesgo = "MEDIO"
        prediccion = "Se√±ales moderadas de riesgo"
    else:
        nivel_riesgo = "BAJO"
        prediccion = "Sin indicadores claros de depresi√≥n"
    
    return {
        'probabilidad': probabilidad,
        'prediccion': prediccion,
        'nivel_riesgo': nivel_riesgo,
        'confianza': abs(probabilidad - 0.5) * 2  # Normalizar confianza 0-1
    }

# ============================================================================
# AGENTE 2: EXPLICABILIDAD XAI (Google Gemini)
# ============================================================================
def crear_agente_explicabilidad():
    """
    Agente 2: Analista de Explicabilidad (XAI)
    Utiliza Gemini para explicar por qu√© el modelo hizo su predicci√≥n
    """
    agente = Agent(
        role='Psic√≥logo Computacional Especialista en XAI',
        goal='Explicar de forma clara y cient√≠fica por qu√© el modelo detect√≥ (o no) indicadores de depresi√≥n en el texto',
        backstory="""Eres un experto en Inteligencia Artificial Explicable (XAI) con maestr√≠a en psicolog√≠a cl√≠nica.
        Tu trabajo es analizar texto y identificar:
        1. Palabras clave emocionales (negativas, desesperanza, aislamiento)
        2. Distorsiones cognitivas (pensamiento catastr√≥fico, generalizaci√≥n excesiva)
        3. Patrones ling√º√≠sticos depresivos (primera persona, tiempo presente, absolutos)
        4. Tono emocional general (tristeza, anhedonia, desesperanza)
        
        Debes proporcionar explicaciones t√©cnicas pero comprensibles, citando ejemplos espec√≠ficos del texto.""",
        verbose=True,
        allow_delegation=False,
        llm=llm
    )
    return agente

def tarea_explicar_prediccion(agente, texto_usuario, resultado_clasificador):
    """
    Tarea para el Agente de Explicabilidad
    """
    tarea = Task(
        description=f"""
        Analiza el siguiente texto de un post de Reddit y explica por qu√© el modelo de Deep Learning 
        predijo una probabilidad de {resultado_clasificador['probabilidad']:.2%} de depresi√≥n.
        
        TEXTO A ANALIZAR:
        "{texto_usuario}"
        
        PREDICCI√ìN DEL MODELO:
        - Probabilidad de depresi√≥n: {resultado_clasificador['probabilidad']:.2%}
        - Nivel de riesgo: {resultado_clasificador['nivel_riesgo']}
        
        INSTRUCCIONES:
        1. Identifica palabras clave espec√≠ficas del texto que indiquen estado emocional
        2. Detecta patrones ling√º√≠sticos asociados con depresi√≥n (uso de pronombres, tiempos verbales, absolutos)
        3. Identifica posibles distorsiones cognitivas (si las hay)
        4. Explica el tono emocional general
        5. Justifica por qu√© el modelo asign√≥ esa probabilidad
        
        IMPORTANTE: S√© espec√≠fico, cita fragmentos exactos del texto y mant√©n un tono profesional pero emp√°tico.
        """,
        expected_output="""Un an√°lisis estructurado con las siguientes secciones:
        - **Palabras clave detectadas**: Lista de t√©rminos emocionales encontrados
        - **Patrones ling√º√≠sticos**: An√°lisis de estructura gramatical y uso del lenguaje
        - **Distorsiones cognitivas**: Identificaci√≥n de sesgos en el pensamiento
        - **Tono emocional**: Descripci√≥n del estado an√≠mico reflejado
        - **Justificaci√≥n de la predicci√≥n**: Explicaci√≥n coherente del score del modelo
        """,
        agent=agente
    )
    return tarea

# ============================================================================
# AGENTE 3: SUPERVISOR/DECISOR FINAL (Google Gemini)
# ============================================================================
def crear_agente_supervisor():
    """
    Agente 3: Supervisor Cl√≠nico
    Toma la decisi√≥n final y genera recomendaciones
    """
    agente = Agent(
        role='Supervisor Cl√≠nico de Salud Mental',
        goal='Tomar la decisi√≥n final sobre el nivel de intervenci√≥n necesario y proporcionar recomendaciones apropiadas',
        backstory="""Eres un psiquiatra con 15 a√±os de experiencia en salud mental digital.
        Tu responsabilidad es revisar los an√°lisis del clasificador y del explicador, y decidir:
        
        - RIESGO ALTO (‚â•70%): Generar alerta cl√≠nica urgente con recomendaciones de intervenci√≥n inmediata
        - RIESGO MEDIO (40-69%): Sugerir monitoreo cercano y recursos de apoyo
        - RIESGO BAJO (<40%): Proporcionar mensaje de refuerzo positivo y recursos preventivos
        
        Siempre debes ser emp√°tico, profesional y proporcionar recursos concretos (l√≠neas de ayuda, terapias, apps).""",
        verbose=True,
        allow_delegation=False,
        llm=llm
    )
    return agente

def tarea_decision_final(agente, texto_usuario, resultado_clasificador, explicacion_xai):
    """
    Tarea para el Agente Supervisor
    """
    tarea = Task(
        description=f"""
        Como Supervisor Cl√≠nico, revisa el caso completo y proporciona tu decisi√≥n final.
        
        INFORMACI√ìN DEL CASO:
        
        Texto del usuario:
        "{texto_usuario}"
        
        Resultado del Clasificador (LSTM):
        - Probabilidad de depresi√≥n: {resultado_clasificador['probabilidad']:.2%}
        - Nivel de riesgo: {resultado_clasificador['nivel_riesgo']}
        - Confianza del modelo: {resultado_clasificador['confianza']:.2%}
        
        An√°lisis de Explicabilidad (XAI):
        {explicacion_xai}
        
        TU TAREA:
        1. Eval√∫a la coherencia entre la predicci√≥n del modelo y el an√°lisis XAI
        2. Determina el nivel de intervenci√≥n requerido:
           - ALERTA CL√çNICA URGENTE (riesgo alto)
           - MONITOREO Y APOYO (riesgo medio)
           - REFUERZO POSITIVO (riesgo bajo)
        
        3. Proporciona recomendaciones espec√≠ficas:
           - L√≠neas de ayuda (Espa√±a: 024, M√©xico: 800 290 0024, etc.)
           - Tipos de terapia recomendados
           - Recursos digitales (apps, comunidades de apoyo)
           - Acciones inmediatas a tomar
        
        4. Redacta un mensaje final para el usuario (emp√°tico pero profesional)
        """,
        expected_output="""Un informe de supervisi√≥n con:
        - **Decisi√≥n cl√≠nica**: Nivel de intervenci√≥n determinado
        - **Justificaci√≥n**: Por qu√© se tom√≥ esa decisi√≥n
        - **Recomendaciones espec√≠ficas**: Lista de recursos y acciones
        - **Mensaje para el usuario**: Comunicaci√≥n emp√°tica y orientadora
        - **Pr√≥ximos pasos**: Qu√© debe hacer el usuario de inmediato
        """,
        agent=agente
    )
    return tarea

# ============================================================================
# FUNCI√ìN PRINCIPAL: ORQUESTACI√ìN DE AGENTES CON CREWAI
# ============================================================================
def ejecutar_sistema_multiagente(titulo, cuerpo):
    """
    Orquesta los 3 agentes para analizar el texto del usuario
    
    Flujo:
    1. Agente Clasificador ‚Üí Predicci√≥n LSTM
    2. Agente XAI ‚Üí Explicaci√≥n de la predicci√≥n
    3. Agente Supervisor ‚Üí Decisi√≥n final y recomendaciones
    """
    
    # Combinar t√≠tulo y cuerpo
    texto_completo = f"{titulo}. {cuerpo}"
    
    # ========== AGENTE 1: CLASIFICADOR ==========
    with st.spinner("üîç Agente 1: Analizando con modelo LSTM..."):
        resultado_clasificador = agente_clasificador(texto_completo)
    
    st.success(f"‚úÖ Clasificador completado: {resultado_clasificador['prediccion']}")
    
    # ========== AGENTE 2: EXPLICABILIDAD ==========
    with st.spinner("üß† Agente 2: Generando explicaci√≥n XAI con Gemini..."):
        agente_xai = crear_agente_explicabilidad()
        tarea_xai = tarea_explicar_prediccion(agente_xai, texto_completo, resultado_clasificador)
        
        crew_xai = Crew(
            agents=[agente_xai],
            tasks=[tarea_xai],
            process=Process.sequential,
            verbose=True
        )
        
        resultado_xai = crew_xai.kickoff()
        explicacion_xai = resultado_xai.raw if hasattr(resultado_xai, 'raw') else str(resultado_xai)
    
    st.success("‚úÖ Explicabilidad completada")
    
    # ========== AGENTE 3: SUPERVISOR ==========
    with st.spinner("üë®‚Äç‚öïÔ∏è Agente 3: Supervisor generando recomendaciones..."):
        agente_supervisor = crear_agente_supervisor()
        tarea_supervisor = tarea_decision_final(
            agente_supervisor, 
            texto_completo, 
            resultado_clasificador, 
            explicacion_xai
        )
        
        crew_supervisor = Crew(
            agents=[agente_supervisor],
            tasks=[tarea_supervisor],
            process=Process.sequential,
            verbose=True
        )
        
        resultado_supervisor = crew_supervisor.kickoff()
        decision_final = resultado_supervisor.raw if hasattr(resultado_supervisor, 'raw') else str(resultado_supervisor)
    
    st.success("‚úÖ Supervisi√≥n completada")
    
    return {
        'clasificador': resultado_clasificador,
        'explicacion': explicacion_xai,
        'decision': decision_final
    }

# ============================================================================
# INTERFAZ DE USUARIO PRINCIPAL
# ============================================================================

# Header
st.markdown('<p class="main-header">üß† MindSentinel</p>', unsafe_allow_html=True)
st.markdown('<p class="sub-header">Sistema Multi-Agente para Monitoreo de Salud Mental en Redes Sociales</p>', unsafe_allow_html=True)

# Sidebar con informaci√≥n
with st.sidebar:
    st.image("https://raw.githubusercontent.com/microsoft/fluentui-emoji/main/assets/Brain/3D/brain_3d.png", width=100)
    st.title("Informaci√≥n del Sistema")
    
    st.markdown("""
    ### üèóÔ∏è Arquitectura
    **3 Agentes Especializados:**
    
    1. ü§ñ **Clasificador** (LSTM Bidireccional)
       - Analiza el texto con Deep Learning
       - Genera probabilidad de depresi√≥n
    
    2. üß† **Explicador XAI** (Gemini Flash)
       - Explica la predicci√≥n del modelo
       - Identifica patrones ling√º√≠sticos
    
    3. üë®‚Äç‚öïÔ∏è **Supervisor Cl√≠nico** (Gemini Flash)
       - Toma decisi√≥n final
       - Genera recomendaciones
    
    ### üìä M√©tricas del Modelo
    """)
    
    col1, col2 = st.columns(2)
    with col1:
        st.metric("Accuracy", f"{config['test_accuracy']:.2%}")
        st.metric("Precision", f"{config['test_precision']:.2%}")
    with col2:
        st.metric("AUC-ROC", f"{config['test_auc']:.2%}")
        st.metric("Recall", f"{config['test_recall']:.2%}")
    
    st.markdown("---")
    st.markdown("""
    ### ‚ö†Ô∏è Aviso Importante
    Este sistema es una herramienta de **apoyo acad√©mico**.
    NO reemplaza el diagn√≥stico profesional.
    
    **En crisis, contacta:**
    - üá™üá∏ Espa√±a: 024
    - üá≤üáΩ M√©xico: 800 290 0024
    - üá¶üá∑ Argentina: 135
    """)

# √Årea principal de entrada
st.markdown("## üìù Simula un Post de Reddit")

col1, col2 = st.columns([1, 1])

with col1:
    titulo = st.text_input(
        "T√≠tulo del Post",
        placeholder="Ej: No s√© qu√© hacer con mi vida...",
        help="Escribe el t√≠tulo como aparecer√≠a en Reddit"
    )

with col2:
    subreddit = st.selectbox(
        "Subreddit",
        ["r/depression", "r/mentalhealth", "r/anxiety", "r/therapy", "r/offmychest"],
        help="Contexto del subreddit (informativo)"
    )

cuerpo = st.text_area(
    "Cuerpo del Post (Body)",
    placeholder="""Escribe aqu√≠ el contenido del post...

Ejemplo:
√öltimamente me siento completamente vac√≠o. No encuentro motivaci√≥n para hacer nada, ni siquiera las cosas que antes me gustaban. Siento que soy una carga para todos y que nada tiene sentido. No s√© si esto va a mejorar alg√∫n d√≠a...""",
    height=200,
    help="Contenido principal del post que ser√° analizado"
)

# Bot√≥n de an√°lisis
col1, col2, col3 = st.columns([1, 2, 1])
with col2:
    analizar_btn = st.button("üîç Analizar con MindSentinel", type="primary", use_container_width=True)

# Procesamiento
if analizar_btn:
    if not titulo or not cuerpo:
        st.error("‚ö†Ô∏è Por favor completa tanto el t√≠tulo como el cuerpo del post")
    elif len(cuerpo) < 20:
        st.warning("‚ö†Ô∏è El texto es muy corto. Escribe al menos 20 caracteres para un an√°lisis preciso.")
    else:
        # Mostrar el post simulado
        with st.expander("üìÑ Post a analizar", expanded=True):
            st.markdown(f"### {titulo}")
            st.markdown(f"*Publicado en {subreddit} ‚Ä¢ {datetime.now().strftime('%d/%m/%Y %H:%M')}*")
            st.markdown(f"{cuerpo}")
        
        st.markdown("---")
        st.markdown("## ü§ñ An√°lisis del Sistema Multi-Agente")
        
        # Ejecutar sistema multi-agente
        try:
            resultados = ejecutar_sistema_multiagente(titulo, cuerpo)
            
            # ========== RESULTADOS DEL CLASIFICADOR ==========
            st.markdown("### 1Ô∏è‚É£ Agente Clasificador (Deep Learning)")
            
            prob = resultados['clasificador']['probabilidad']
            nivel = resultados['clasificador']['nivel_riesgo']
            
            # Determinar clase CSS
            if nivel == "ALTO":
                css_class = "high-risk"
                emoji = "üî¥"
            elif nivel == "MEDIO":
                css_class = "medium-risk"
                emoji = "üü°"
            else:
                css_class = "low-risk"
                emoji = "üü¢"
            
            st.markdown(f"""
            <div class="prediction-box {css_class}">
                <h2>{emoji} Nivel de Riesgo: {nivel}</h2>
                <p style="font-size: 1.5rem; margin: 10px 0;">
                    <strong>Probabilidad de Depresi√≥n: {prob:.1%}</strong>
                </p>
                <p>{resultados['clasificador']['prediccion']}</p>
                <p><em>Confianza del modelo: {resultados['clasificador']['confianza']:.1%}</em></p>
            </div>
            """, unsafe_allow_html=True)
            
            # Barra de progreso visual
            st.progress(prob)
            
            # ========== EXPLICACI√ìN XAI ==========
            st.markdown("### 2Ô∏è‚É£ Agente Explicador (XAI con Gemini)")
            with st.container():
                st.markdown(f"""
                <div class="agent-card">
                {resultados['explicacion']}
                </div>
                """, unsafe_allow_html=True)
            
            # ========== DECISI√ìN FINAL ==========
            st.markdown("### 3Ô∏è‚É£ Agente Supervisor (Decisi√≥n Cl√≠nica)")
            with st.container():
                st.markdown(f"""
                <div class="agent-card">
                {resultados['decision']}
                </div>
                """, unsafe_allow_html=True)
            
            # ========== RECURSOS ADICIONALES ==========
            st.markdown("---")
            st.markdown("## üìû Recursos de Ayuda Inmediata")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.info("""
                **üá™üá∏ Espa√±a**
                - Tel√©fono: 024
                - Servicio 24/7 gratuito
                """)
            
            with col2:
                st.info("""
                **üá≤üáΩ M√©xico**
                - Tel√©fono: 800 290 0024
                - SAPTEL 24 horas
                """)
            
            with col3:
                st.info("""
                **üåç Internacional**
                - findahelpline.com
                - Recursos por pa√≠s
                """)
            
        except Exception as e:
            st.error(f"‚ùå Error durante el an√°lisis: {str(e)}")
            st.info("Verifica que la GOOGLE_API_KEY est√© correctamente configurada")

# Footer
st.markdown("---")
st.markdown("""
<div style="text-align: center; color: #666; font-size: 0.9rem;">
    <p><strong>MindSentinel</strong> ‚Ä¢ Sistema Multi-Agente para Salud Mental</p>
    <p>Desarrollado con ‚ù§Ô∏è usando TensorFlow, CrewAI y Google Gemini</p>
    <p><em>‚ö†Ô∏è Herramienta acad√©mica - No sustituye atenci√≥n m√©dica profesional</em></p>
</div>
""", unsafe_allow_html=True)
